{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#1) What is Simple Linear Regression?\n",
        "Ans)\n",
        "Simple Linear Regression is a statistical method used to model the relationship between one independent variable (X) and one dependent variable (Y) using a straight line.\n",
        "\n",
        "It finds the best-fitting line of the form:\n",
        "\n",
        "Y=a+bX\n",
        "where\n",
        "\n",
        "a = intercept\n",
        "\n",
        "b = slope (rate of change in Y for a one-unit change in X)\n",
        "\n",
        "It is used to predict the value of Y based on X."
      ],
      "metadata": {
        "id": "Yd4CYbjZDz2z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2) What are the key assumptions of Simple Linear Regression?\n",
        "Ans)\n",
        "* **Linearity** - The relationship between X and Y must be linear.\n",
        "\n",
        "* **Independence** - Observations must be independent of each other.\n",
        "\n",
        "* **Homoscedasticity** - The variance of errors (residuals) should be constant across all values of X.\n",
        "\n",
        "* **Normality of errors** - The residuals should be normally distributed.\n",
        "\n",
        "* **No perfect multicollinearity** - Not relevant here because there is only one X, but X should not be a constant.\n"
      ],
      "metadata": {
        "id": "xwAdjNh3ELaJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3) What does the coefficient m represent in the equation Y=mX+c?\n",
        "\n",
        "Ans) In the equation Y = mX + c, the coefficient m represents the slope of the line — it tells you how much Y changes for a one-unit increase in X."
      ],
      "metadata": {
        "id": "lqmwEIE8E4Xi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4) What does the intercept c represent in the equation Y = mX+c?\n",
        "Ans)\n",
        "In the equation Y = mX + c, the intercept (c) represents the value of Y when X = 0.\n",
        "It is the point where the regression line crosses the Y-axis.\n"
      ],
      "metadata": {
        "id": "Xb5lgXiHFJcg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5) How do we calculate the slope m in Simple Linear Regression?\n",
        "Ans)\n",
        "m = sum((Xi - x_mean)(Yi - y_mean)) / sum((Xi - x_mean)²)"
      ],
      "metadata": {
        "id": "PeoAC1YQFryO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6) what is the purpose of least squares method in Simple Linear Regression?\n",
        "\n",
        "Ans)\n",
        "Find the best-fitting line by minimizing the sum of the squared differences between the actual values and the predicted values."
      ],
      "metadata": {
        "id": "IMa7CjRfGnHD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sbXBeeO8H-TY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7) How is the coefficient of determination (R_square) interpreted in Simple Linear Regression?\n",
        "\n",
        "Ans)\n",
        "\n",
        "The coefficient of determination (R_square) tells us how much of the variation in the dependent variable (Y) is explained by the independent variable (X) in the regression model.\n",
        "\n",
        "\n",
        "R_square = 0 -> X explains none of the variation in Y.\n",
        "\n",
        "R_square = 1 -> X explains all of the variation in Y.\n",
        "\n",
        "Higher R_square -> Better fit of the model.\n"
      ],
      "metadata": {
        "id": "MJi6eA21HBKC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8) What is the Multiple Linear Regression?\n",
        "\n",
        "Ans)\n",
        "Multiple Linear Regression is a statistical method used to model the relationship between one dependent variable (Y) and two or more independent variables"
      ],
      "metadata": {
        "id": "0pcswjReH7bn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9) What is the main difference between Simple and Multiple Linear Regression?\n",
        "\n",
        "Ans)\n",
        "* Simple Linear Regression uses one independent variable (X) to predict Y.\n",
        "* Multiple Linear Regression uses two or more independent variables to predict Y.\n"
      ],
      "metadata": {
        "id": "66RQB7o5IVuq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10) What are the key assumptions of Multiple Linear Regression?\n",
        "Ans)\n",
        "* Linearity - The relationship between each independent variable and the dependent variable is linear.\n",
        "\n",
        "* Independence of errors - Residuals are independent.\n",
        "\n",
        "* Homoscedasticity - Constant variance of residuals across all levels of predictors.\n",
        "\n",
        "* Normality of residuals - Errors should be normally distributed.\n",
        "\n",
        "* No multicollinearity - Independent variables should not be highly correlated with each other.\n",
        "\n",
        "* No autocorrelation - Especially important in time-series data."
      ],
      "metadata": {
        "id": "vjCqh_aWI0tY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#11) What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression Model?\n",
        "\n",
        "Ans)\n",
        "Heteroscedasticity means that the variance of the residuals (errors) is not constant across all levels of the independent variables.\n",
        "\n",
        "Effect on Multiple Linear Regression:\n",
        "\n",
        "It does not change the coefficients, but\n",
        "\n",
        "It makes the standard errors unreliable, leading to:\n",
        "\n",
        "* Incorrect t-tests\n",
        "\n",
        "* Incorrect p-values\n",
        "\n",
        "Unreliable confidence intervals"
      ],
      "metadata": {
        "id": "Q24HDXZDJdpE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#12) How can you improve a Multiple Linear Regression model with high multicollinearity?\n",
        "Ans)\n",
        "We can improve a Multiple Linear Regression model with high multicollinearity using these methods:\n",
        "\n",
        "* Remove one of the highly correlated variables.\n",
        "\n",
        "* Combine correlated variables (e.g., using PCA or creating an index).\n",
        "\n",
        "* Use Regularization techniques like Ridge Regression or Lasso Regression.\n",
        "\n",
        "* Increase sample size, if possible.\n"
      ],
      "metadata": {
        "id": "KqQzoDyQJ439"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#13) What are some common techniques for transforming categorical variable for use in regression models?\n",
        "Ans)\n",
        "Common techniques for transforming categorical variables for use in regression models include:\n",
        "\n",
        "* One-Hot Encoding - Converts categories into 0/1 dummy variables.\n",
        "\n",
        "* Label Encoding - Assigns each category a numerical value.\n",
        "\n",
        "* Ordinal Encoding - Used when categories have a natural order.\n",
        "\n",
        "* Binary Encoding - Converts categories into binary digits (useful for high-cardinality data).\n",
        "\n",
        "* Target Encoding - Replaces categories with the mean of the target variable"
      ],
      "metadata": {
        "id": "vqoP6QwZKiVl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#14)What is the role of interaction terms in Multiple Linear Regression?\n",
        "Ans)\n",
        "Interaction terms in Multiple Linear Regression show how two independent variables together influence the dependent variable.\n",
        "\n",
        "They capture situations where the effect of one variable depends on the value of another variable."
      ],
      "metadata": {
        "id": "vIfuRk5-Kx5k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#15)  How can the interpretation of intercept differ between Simple and Multiple Linear Regression?\n",
        "Ans)\n",
        "1. Simple Linear Regression:\n",
        "\n",
        "* Intercept c is the predicted value of Y when the single X = 0.\n",
        "\n",
        "2. Multiple Linear Regression:\n",
        "\n",
        "* Intercept b₀ is the predicted value of Y when all independent variables"
      ],
      "metadata": {
        "id": "6PaymETvLWbB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#16)  What is the significance of the slope in regression analysis, and how does it affect predictions?\n",
        "Ans)\n",
        "The slope in regression analysis represents the rate of change of the dependent variable (Y) with respect to an independent variable (X).\n",
        "\n",
        "Significance:\n",
        "\n",
        "Indicates strength and direction of the relationship:\n",
        "\n",
        "Positive slope -> Y increases as X increases.\n",
        "\n",
        "Negative slope -> Y decreases as X increases.\n",
        "\n",
        "Effect on predictions:\n",
        "\n",
        "A larger magnitude of the slope means X has a bigger impact on predicted Y.\n",
        "\n",
        "Accurate slope estimation ensures reliable predictions for new X values."
      ],
      "metadata": {
        "id": "WPvrk98LLrQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#17) How does the intercept in a regression model provide context for the relationship between variables?\n",
        "Ans)\n",
        "The intercept in a regression model provides a baseline value of the dependent variable (Y) when all independent variables (X's) are zero.\n",
        "\n",
        "Context it provides:\n",
        "\n",
        "Shows the starting point of Y before any effect of X is applied.\n",
        "\n",
        "Helps anchor the regression line on the Y-axis.\n",
        "\n",
        "In multiple regression, it indicates Y when all predictors are at their reference level."
      ],
      "metadata": {
        "id": "0fLwwKWtMHaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#18) What are the limitations of using R_square as a sole measure of model performance?\n",
        "Ans)\n",
        "* Doesn't indicate model accuracy - High R² doesn't mean predictions are correct.\n",
        "\n",
        "* Ignores overfitting - Adding more variables can increase R² even if they are irrelevant.\n",
        "\n",
        "* Doesn't assess bias - R² doesn't show if the model systematically over- or under-predicts.\n",
        "\n",
        "* Not suitable for non-linear models - Only measures linear fit.\n",
        "\n",
        "* Doesn't account for variable importance - R² cannot tell which predictors are most influential."
      ],
      "metadata": {
        "id": "0IsgjoTYMkZc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#19) How would you interpret a large standard error for a regression coefficient?\n",
        "Ans)\n",
        "* The coefficient may vary widely if the model is repeated with new data.\n",
        "\n",
        "* It leads to wider confidence intervals and less reliable hypothesis tests (t-tests).\n",
        "\n",
        "* Suggests weak evidence that the predictor has a real effect on the dependent variable."
      ],
      "metadata": {
        "id": "S0c_hIY0M9I8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#20) How can heteroscedasticity be identified in residual plots, and why is it important to address it?\n",
        "Ans)\n",
        "* Plot residuals vs. predicted values.\n",
        "\n",
        "* If the spread of residuals increases or decreases as predicted values increase (funnel or cone shape), heteroscedasticity is present.\n",
        "\n",
        "* Ideally, residuals should be randomly scattered with constant variance."
      ],
      "metadata": {
        "id": "N4X_4S5zNaXL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#21) What does it mean if a multiple linear regression model has a high R_square but low adjusted R_square?\n",
        "Ans)\n",
        "* High R_square -> The model explains a large portion of the variation in Y.\n",
        "\n",
        "* Low Adjusted R_square -> Some predictors do not contribute meaningfully and may be inflating R²."
      ],
      "metadata": {
        "id": "_QW3QFDjOLIA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#22) Why is it important to scale variables in Multiple Linear Regression?\n",
        "Ans)\n",
        "* **Ensures comparability** - Predictors measured on different scales don't dominate the model.\n",
        "\n",
        "* **Improves numerical stability** - Reduces computational issues in matrix calculations.\n",
        "\n",
        "* **Helps regularization** - Techniques like Ridge or Lasso assume scaled inputs.\n",
        "\n",
        "* **Affects interpretation** - Coefficients reflect the effect per unit change, so scaling makes them comparable."
      ],
      "metadata": {
        "id": "kxERoDAsOlvC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#23) What is polynomial regression?\n",
        "Ans)\n",
        "Polynomial Regression is an extension of linear regression where the relationship between the independent variable (X) and dependent variable (Y) is modeled as a polynomial instead of a straight line."
      ],
      "metadata": {
        "id": "vX-vttA6PP0N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#24) How does polynomial regression differ from linear regressoin?\n",
        "Ans)\n",
        "**Linear Regression:**\n",
        "* Models a straight-line relationship between X and Y.\n",
        "* Assumes linear relationship.\n",
        "\n",
        "**Polynomial Regression:**\n",
        "* Models a curved (non-linear) relationship.\n",
        "* Can capture complex patterns in data."
      ],
      "metadata": {
        "id": "TLDy6wtqP36P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#25) When is polynomial regression used?\n",
        "Ans)\n",
        "* The relationship between independent (X) and dependent (Y) variables is non-linear.\n",
        "\n",
        "* Linear regression underfits the data and cannot capture the curvature.\n",
        "\n",
        "* You want to model trends, peaks, or curves in data, e.g., growth rates, stock prices, or temperature changes.\n"
      ],
      "metadata": {
        "id": "EhpECC7fQiAe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#26) What is the general equation for polynomial regression?\n",
        "Ans)\n",
        "Y = b₀ + b₁X + b₂X² + … + bₙXⁿ\n"
      ],
      "metadata": {
        "id": "CWzAiQPkRxqW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#27) Can ploynomial regression be applied to multiple variables?\n",
        "Ans)\n",
        "Yes, polynomial regression can be applied to multiple variables, and it is called multivariate polynomial regression.\n"
      ],
      "metadata": {
        "id": "GQ3LDR4QSCXG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#28) What are the limitations of polynomial regressoin?\n",
        "Ans)\n",
        "Polynomial regression can overfit, is hard to interpret, and performs poorly outside the data range."
      ],
      "metadata": {
        "id": "AiFKLJVmSzVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#29) What methods can be used to evaluate model fit when selecting the degree of a polynomial?\n",
        "Ans)\n",
        "* Mean Squared Error (MSE) / Root MSE (RMSE) - Lower values indicate better fit.\n",
        "\n",
        "* Cross-Validation - Splitting data into folds to check performance on unseen data.\n",
        "\n",
        "* Residual Plots - Check for patterns; random residuals indicate good fit.\n",
        "\n",
        "* Akaike Information Criterion (AIC) / Bayesian Information Criterion (BIC) - Penalize model complexity."
      ],
      "metadata": {
        "id": "Ra3BB8fiTCWm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#30)  Why is visualization important in polynomial regression?\n",
        "Ans)\n",
        "* Shows the curve fit - Helps see if the polynomial captures the data trend.\n",
        "\n",
        "* Detects underfitting or overfitting - Too flat -> underfit; too wiggly -> overfit.\n",
        "\n",
        "* Identifies outliers - Points far from the curve are easily spotted.\n",
        "\n",
        "* Improves understanding - Makes complex non-linear relationships easier to interpret."
      ],
      "metadata": {
        "id": "Gn2n23UJTtzb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#31) How is polynomial regression implemented in Python?\n",
        "Ans)\n"
      ],
      "metadata": {
        "id": "787Y9cVzUdNJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bw8gPRVzDgKt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba3b28e6-a9d9-4ba7-c9e9-cab23b45b308"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.  4.  9. 16. 25.]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import numpy as np\n",
        "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)\n",
        "Y = np.array([1, 4, 9, 16, 25])\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "X_poly = poly.fit_transform(X)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_poly, Y)\n",
        "\n",
        "Y_pred = model.predict(X_poly)\n",
        "print(Y_pred)\n"
      ]
    }
  ]
}